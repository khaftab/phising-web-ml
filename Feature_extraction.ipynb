{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3JSeGy0vuq7"
      },
      "outputs": [],
      "source": [
        "# importing required packages for this section\n",
        "from urllib.parse import urlparse,urlencode\n",
        "import ipaddress\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27RmQdjF17j9"
      },
      "outputs": [],
      "source": [
        "def havingIP(url):\n",
        "  try:\n",
        "    ipaddress.ip_address(url)\n",
        "    ip = 1\n",
        "  except:\n",
        "    ip = 0\n",
        "  return ip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "print(\"scikit-learn version:\", sklearn.__version__)\n"
      ],
      "metadata": {
        "id": "uzfXIGAs86jA",
        "outputId": "c27d11a2-9194-42b2-ff8c-40b1c2db2f30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learn version: 1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua2CjwNO2DeJ"
      },
      "outputs": [],
      "source": [
        "def haveAtSign(url):\n",
        "  if \"@\" in url:\n",
        "    at = 1\n",
        "  else:\n",
        "    at = 0\n",
        "  return at"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3piTbTqu_Xg"
      },
      "outputs": [],
      "source": [
        "def getLength(url):\n",
        "    # Remove common prefixes\n",
        "    prefixes = ['http://', 'https://']\n",
        "    for prefix in prefixes:\n",
        "        if url.startswith(prefix):\n",
        "            url = url[len(prefix):]\n",
        "\n",
        "    # Remove 'www.' if present\n",
        "    url = url.replace('www.', '')\n",
        "\n",
        "    # Return the length of the remaining URL\n",
        "    if len(url) < 54:\n",
        "      length = 0\n",
        "    else:\n",
        "      length = 1\n",
        "    return length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hl3E6POvIAX",
        "outputId": "d7cca94f-b3ec-4053-a546-105e1e56a9ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "getLength(\"https://example.com.df.bd.thisissdummy-url-that-nmeed-fdfdf-dfjdsfjdsifjdsofsdfjldf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_47MZhd0vXjM"
      },
      "outputs": [],
      "source": [
        "def getDepth(url):\n",
        "  s = urlparse(url).path.split('/')\n",
        "  depth = 0\n",
        "  for j in range(len(s)):\n",
        "    if len(s[j]) != 0:\n",
        "      depth = depth+1\n",
        "  return depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVeAjxERviJO",
        "outputId": "f26200d6-96e0-4d46-f210-cf312257ffba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "getDepth(\"https://microsoft.com/product/page-3/34\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tscP2xvTv8g1"
      },
      "outputs": [],
      "source": [
        "def redirection(url):\n",
        "  pos = url.rfind('//')\n",
        "  if pos > 6:\n",
        "    if pos > 7:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "  else:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bL0t8w8v-D3",
        "outputId": "677ebff5-8ef3-4859-b2fc-60996fcb9b95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "redirection(\"https://10fastfingers.com/widgets//typingtest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fx8v6MTwmQz"
      },
      "outputs": [],
      "source": [
        "def httpDomain(url):\n",
        "  domain = urlparse(url).netloc\n",
        "  if 'https' in domain:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qALgv70HwnMb",
        "outputId": "32c025e3-dc63-48e8-e4cd-ed2311cdfc5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "httpDomain(\"http://https-example.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaCWRlzV4QsD"
      },
      "outputs": [],
      "source": [
        "def secureHttp(url):\n",
        "    return int(urlparse(url).scheme == 'https')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZR8dIkrxKYR"
      },
      "outputs": [],
      "source": [
        "shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
        "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
        "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
        "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
        "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
        "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
        "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
        "                      r\"tr\\.im|link\\.zip\\.net\"\n",
        "\n",
        "# 8. Checking for Shortening Services in URL (Tiny_URL)\n",
        "def tinyURL(url):\n",
        "    match=re.search(shortening_services,url)\n",
        "    if match:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZrKjvISxLyj",
        "outputId": "807f2284-ffd4-47b1-f9a6-9cc74f9e2641"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tinyURL(\"google.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUM_3Ly3xfSr"
      },
      "outputs": [],
      "source": [
        "# 9.Checking for Prefix or Suffix Separated by (-) in the Domain (Prefix/Suffix)\n",
        "def prefixSuffix(url):\n",
        "    if '-' in urlparse(url).netloc:\n",
        "        return 1            # phishing\n",
        "    else:\n",
        "        return 0            # legitimate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDk7pwC1xgdM",
        "outputId": "b17805ea-5021-42d0-9093-9d8c477ad2e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "prefixSuffix(\"https://youtube-hak.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX6tvwezxnVr",
        "outputId": "3a53dac9-22a7-4ccc-885a-8deae071ba26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-whois\n",
            "  Downloading python_whois-0.9.4-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from python-whois) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->python-whois) (1.16.0)\n",
            "Installing collected packages: python-whois\n",
            "Successfully installed python-whois-0.9.4\n",
            "Collecting tldextract\n",
            "  Downloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.7)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract) (2.31.0)\n",
            "Collecting requests-file>=1.4 (from tldextract)\n",
            "  Downloading requests_file-2.0.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2024.2.2)\n",
            "Installing collected packages: requests-file, tldextract\n",
            "Successfully installed requests-file-2.0.0 tldextract-5.1.2\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "!pip install python-whois\n",
        "!pip install tldextract\n",
        "import whois\n",
        "import urllib\n",
        "import urllib.request\n",
        "from datetime import datetime\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdYHD9XY3kyU",
        "outputId": "2fe51251-1697-4055-b48a-75c914cbb37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Domain age in days: 1\n"
          ]
        }
      ],
      "source": [
        "import whois\n",
        "from datetime import datetime\n",
        "\n",
        "def domainAge(url):\n",
        "    try:\n",
        "        domain = url.split(\"//\")[-1].split(\"/\")[0]\n",
        "        whois_info = whois.whois(domain)\n",
        "        creation_date = whois_info.creation_date\n",
        "        if isinstance(creation_date, list):\n",
        "            creation_date = creation_date[0]\n",
        "        if isinstance(creation_date, datetime):\n",
        "            now = datetime.now()\n",
        "            age = now - creation_date\n",
        "            return age.days\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    return 1\n",
        "\n",
        "# Example usage\n",
        "url = \"'https://dyuvstyfawecteraw.blogspot.de/?ref=aGFuc2pvZXJnc0BnbXguZGU'\"\n",
        "age = domainAge(url)\n",
        "print(f\"Domain age in days: {age}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asygXZIK3n3i"
      },
      "outputs": [],
      "source": [
        "# Subdomains Count:\n",
        "\n",
        "\n",
        "\n",
        "import tldextract\n",
        "\n",
        "def subdomainsCount(url):\n",
        "    extracted = tldextract.extract(url)\n",
        "    return len(extracted.subdomain.split('.'))\n",
        "\n",
        "# url = \"https://www.haka.example.com\"\n",
        "# print(subdomainsCount(url))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcIUQcJvGXwp"
      },
      "outputs": [],
      "source": [
        "# End Period of Domain\n",
        "\n",
        "from datetime import datetime\n",
        "import whois\n",
        "\n",
        "def domainEnd(url):\n",
        "    try:\n",
        "        domain = url.split(\"//\")[-1].split(\"/\")[0]\n",
        "        domain_info = whois.whois(domain)\n",
        "        expiration_date = domain_info.expiration_date\n",
        "\n",
        "        if isinstance(expiration_date, list):\n",
        "            expiration_date = expiration_date[0]\n",
        "\n",
        "        if isinstance(expiration_date, datetime):\n",
        "            current_time = datetime.now()\n",
        "            remaining_time = expiration_date - current_time\n",
        "            remaining_months = remaining_time.days / 30\n",
        "\n",
        "            if remaining_months < 3:\n",
        "                return 1  # Phishing\n",
        "            else:\n",
        "                return 0  # Legitimate\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "    return 1\n",
        "\n",
        "# Example usage\n",
        "# url = \"https://www.sffd34.com\"\n",
        "# end_period = get_end_period_of_domain(url)\n",
        "# print(f\"End Period of Domain for {url}: {end_period}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCP7pZwAtrU7"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def iframe(response):\n",
        "    if response == \"\":\n",
        "        return 1\n",
        "    try:\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            iframes = soup.find_all('iframe')\n",
        "            for iframe in iframes:\n",
        "                src = iframe.get('src', '')\n",
        "                if not src:\n",
        "                    return 1  # Phishing\n",
        "                iframe_response = requests.get(src)\n",
        "                if iframe_response.status_code != 200:\n",
        "                    return 1  # Phishing\n",
        "            return 0  # Legitimate\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    return 0  # Return 0 for legitimate URLs by default\n",
        "\n",
        "# Example usage\n",
        "# url = \"http://chami.com/html-kit/plugins/info/hkthumbnailstarter/\"\n",
        "# empty_iframe = iframe(url)\n",
        "# print(f\"Empty Iframe: {empty_iframe}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKf824hEttPD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def fakeStatusBar(response):\n",
        "    if response == \"\":\n",
        "        return 1\n",
        "    try:\n",
        "        if response.status_code == 200:\n",
        "            if not response.text:  # Check if response is empty\n",
        "                return 1  # Phishing\n",
        "            # Search for onmouseover event in the response text\n",
        "            if re.search(r\"onmouseover\", response.text):\n",
        "                return 1  # Phishing\n",
        "            return 0  # Legitimate\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    return 0  # Return 0 for legitimate URLs by default\n",
        "\n",
        "# Example usage\n",
        "# url = \"http://google.com\"\n",
        "# fake_status_bar = fakeStatusBar(url)\n",
        "# print(f\"Fake Status Bar: {fake_status_bar}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hIeX6kIt4jn"
      },
      "outputs": [],
      "source": [
        "\n",
        "def rightClick(response):\n",
        "    if response == \"\":\n",
        "        return 1\n",
        "    try:\n",
        "        if response.status_code == 200 and \"oncontextmenu\" in response.text:\n",
        "            return 1\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    return 0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIjagj1wTC7W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQi3swcTus_u"
      },
      "outputs": [],
      "source": [
        "def forwarding(response):\n",
        "  if response == \"\":\n",
        "    return 1\n",
        "  else:\n",
        "    if len(response.history) <= 2:\n",
        "      return 0\n",
        "    else:\n",
        "      return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GP5Ks6M4EnU"
      },
      "outputs": [],
      "source": [
        "def addHttpPrefix(domain):\n",
        "  parts = domain.split('#', 1)\n",
        "  domain_part = parts[0]\n",
        "  fragment_part = '#' + parts[1] if len(parts) > 1 else ''\n",
        "\n",
        "  if domain_part.startswith('http://') or domain_part.startswith('https://'):\n",
        "      return domain_part + fragment_part\n",
        "  else:\n",
        "      return 'http://' + domain_part + fragment_part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBwODl9n1q1J",
        "outputId": "dd3d350e-f105-42f8-b24e-7ce4915921e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://chatgpt.com/', 0, 0, 0, 0, 0, 1, 0, 0, 529, 0, 1, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "def featureExtraction(url):\n",
        "  url = addHttpPrefix(url)\n",
        "  features = []\n",
        "  #Address bar based features (10)\n",
        "  #features.append(getDomain(url))\n",
        "  features.append((url))\n",
        "  features.append(haveAtSign(url))\n",
        "  features.append(getLength(url))\n",
        "  features.append(getDepth(url))\n",
        "  features.append(redirection(url))\n",
        "  features.append(httpDomain(url))\n",
        "  features.append(tinyURL(url))\n",
        "  features.append(prefixSuffix(url))\n",
        "\n",
        "  #Domain based features (4)\n",
        "  dns = 0\n",
        "  try:\n",
        "    domain_name = whois.whois(urlparse(url).netloc)\n",
        "  except:\n",
        "    dns = 1\n",
        "\n",
        "  features.append(dns)\n",
        "  # features.append(web_traffic(url))\n",
        "  features.append(1 if dns == 1 else domainAge(url))\n",
        "  features.append(1 if dns == 1 else domainEnd(url))\n",
        "  features.append(subdomainsCount(url))\n",
        "\n",
        "  # HTML & Javascript based features\n",
        "  # try:\n",
        "  #   response = requests.get(url)\n",
        "  #   # print(response.status_code)\n",
        "  # except:\n",
        "  #   response = \"\"\n",
        "  try:\n",
        "    response = requests.get(url, timeout=60)\n",
        "    # print(response.status_code)\n",
        "  except requests.Timeout:\n",
        "    print(\"Timeout error: The request timed out\")\n",
        "    response = \"\"\n",
        "  except requests.RequestException as e:\n",
        "    print(\"Request error:\", e)\n",
        "    response = \"\"\n",
        "\n",
        "  features.append(iframe(response))\n",
        "  features.append(fakeStatusBar(response))\n",
        "  features.append(rightClick(response))\n",
        "  features.append(forwarding(response))\n",
        "\n",
        "  return features\n",
        "\n",
        "#converting the list to dataframe\n",
        "feature_names = ['Have_At','URL_Length','URL_Depth','Redirection','Http_In_Domain',\n",
        "'Tiny_URL','Prefix/Suffix','DNS','Domain_Age','Domain_End','Subdomains_Count','iFrame','Fake_Status_Bar','Right_Click','Forwarding']\n",
        "\n",
        "featureExtraction('https://chatgpt.com/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1EpYFobs1in"
      },
      "outputs": [],
      "source": [
        "# import csv\n",
        "\n",
        "# # List of arrays\n",
        "# arrays = [\n",
        "#     [1, 2, 3],\n",
        "#     [4, 5, 6],\n",
        "#     [7, 8, 9]\n",
        "# ]\n",
        "\n",
        "# # Path to the CSV file\n",
        "# csv_file = 'beingn.csv'\n",
        "\n",
        "# # Writing the arrays to the CSV file\n",
        "# with open(csv_file, mode='w', newline='') as file:\n",
        "#     writer = csv.writer(file)\n",
        "#     for arr in out:\n",
        "#         writer.writerow(arr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBdVydD6yYNw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El-ikKtdzT0d"
      },
      "outputs": [],
      "source": [
        "# data0 = pd.read_csv('new_beign_list.csv')\n",
        "# data0.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNPM63d70eLO"
      },
      "outputs": [],
      "source": [
        "# out = []\n",
        "# for index, row in data0.iterrows():\n",
        "#     if index < 0:\n",
        "#         continue\n",
        "#     if index > 2004:\n",
        "#         break\n",
        "#     value = row['url']\n",
        "#     res = featureExtraction(value)\n",
        "#     out.append(res)\n",
        "#     # print(value)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nU_QDK_DTD9"
      },
      "outputs": [],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpsTfuWWtZRw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('phish_url.csv')\n",
        "\n",
        "# Check each column\n",
        "for column_name in df.columns:\n",
        "    # Check if the column is empty\n",
        "    is_empty = df[column_name].empty\n",
        "\n",
        "    # Check for null values in the column\n",
        "    has_null = df[column_name].isnull().any()\n",
        "\n",
        "    # Check for non-numeric values in the column\n",
        "    try:\n",
        "        pd.to_numeric(df[column_name], errors='raise')\n",
        "        has_non_numeric = False\n",
        "    except ValueError:\n",
        "        has_non_numeric = True\n",
        "\n",
        "    print(f\"Column '{column_name}' is empty: {is_empty}\")\n",
        "    print(f\"Column '{column_name}' has null values: {has_null}\")\n",
        "    print(f\"Column '{column_name}' has non-numeric values: {has_non_numeric}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_csv('beingn.csv')\n",
        "\n",
        "# Specify the column name and the value to fill\n",
        "column_name = 'Label'\n",
        "value_to_fill = '0'\n",
        "\n",
        "# Fill the column with the specified value\n",
        "df[column_name] = value_to_fill\n",
        "\n",
        "# Save the DataFrame back to the Excel file\n",
        "df.to_csv('benign_labled.csv', index=False)\n"
      ],
      "metadata": {
        "id": "tQOnrnljQZrE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}